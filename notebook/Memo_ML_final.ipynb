{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes : étapes d'un projet de ML\n",
    "\n",
    "\n",
    "|N°|Step|Stage|\n",
    "|--------|-----------------------|------------|\n",
    "|1. |Frame the problem and look at the big picture.||\n",
    "|2. |Get the data.||\n",
    "|3. |Explore the data to gain insights.||\n",
    "|4. |Prepare the data to better expose the underlying data patterns to Machine Learning algorithms.||\n",
    "|5. |Explore many different models and shortlist the best ones.||\n",
    "|6. |Fine-tune your models and combine them into a great solution.||\n",
    "|7. |Present your solution.||\n",
    "|8. |Launch, monitor, and maintain your system.||"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Frame the problem and look at the big picture\n",
    "\n",
    "#### - déjà donné dans nos exemples  \n",
    "\n",
    "#### - définir la variable target (cas général)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get the data\n",
    "\n",
    "#### - définir la target (valeurs réelles)\n",
    "\n",
    "#### - dataset déjà donné dans nos exemples\n",
    "\n",
    ">`pd.read_XXX()`  \n",
    ">`sklearn.datasets.load_XXX`  \n",
    "\n",
    "#### - générer des données\n",
    "\n",
    "> `np.linspace()`  \n",
    "> `np.logspace()`\n",
    "\n",
    "#### - clean surtout en enlevant les NA ou en les recodant (cf partie d'après)\n",
    "\n",
    ">`pd.dropna()`  \n",
    ">`pd.fillna()`  \n",
    ">`pd.replace()`  \n",
    ">`pd.rename()`  \n",
    ">`pd.drop()`  \n",
    ">`sklearn.impute.SimpleImputer`  \n",
    "\n",
    "#### - case_when en pandas/numpy :  \n",
    "\n",
    "<font size=2>\n",
    "<code>\n",
    "<pre>\n",
    "conditions=[df['colonne']=='string1',   \n",
    "            df['colonne']=='string2',  \n",
    "            df['colonne']=='string3'  \n",
    "            ]  \n",
    "choices=[1, 2, 3]  \n",
    "df_temp['nouvellecolonne']=np.select(conditions, choices, np.nan).astype(float)  \n",
    "</pre></code></font>  \n",
    "\n",
    "#### - Supprimer selon un type de donnée  \n",
    "\n",
    "> `df.select_dtypes(include='number')`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Explore the data to gain insights\n",
    "\n",
    "#### - regarder la nature des features, la présence de NA\n",
    "\n",
    "> `df.describe()`  \n",
    "> `df.dtypes`  \n",
    "> `df.info()`  \n",
    "> Fonction pour afficher les attributs des variables + la proportion de NA : \n",
    "<font size=2 color=\"grey\">\n",
    "<code>\n",
    "<pre> \n",
    "def table_variable_attributes(df : pd.DataFrame) -> pd.DataFrame:  \n",
    "    \"\"\"Création table avec attributs des variables et % de valeurs manquantes\"\"\"  \n",
    "    df_temp = (pd.DataFrame(  \n",
    "        {  \n",
    "            'variable' : df.isna().describe(include=\"all\").columns,  \n",
    "            'count' : df.isna().describe(include=\"all\").loc['count'].astype(float),  \n",
    "            'unique' : df.isna().describe(include=\"all\").loc['unique'].astype(float),  \n",
    "            'top' : df.isna().describe(include=\"all\").loc['top'].astype(str),  \n",
    "            'freq_top' : df.isna().describe(include=\"all\").loc['freq'].astype(float)  \n",
    "            # \"unique\" dit s'il y a des na ou pas dans la colonne (1=pas de NA, 2 = présence de Na)  \n",
    "            # \"count\" nous donne le nb de lignes total  \n",
    "            # \"freq\" nous donne le nb de lignes du \"top\"  \n",
    "        }  \n",
    "    )  \n",
    "    .assign(percent_top=lambda df : df['freq_top']/df['count'])  \n",
    "    .reset_index()  \n",
    "    .assign(percent_na = lambda df : [df.loc[:,'percent_top'][row] if df['top'][row]=='True' else 1-df['percent_top'][row] for row in df.index] )  \n",
    "    .drop(columns=['percent_top', 'index', 'unique', 'top', 'freq_top'])  \n",
    "    .assign(percent_na=lambda df : round(df['percent_na']*100, 0),  \n",
    "            count=lambda df : df['count'].astype(int))  \n",
    "    .assign(type_variable = df.dtypes.astype(str).tolist())  \n",
    "    )  \n",
    "    return df_temp  \n",
    "    </pre> </code> </font>\n",
    "\n",
    "#### - histogrammes, boxplot, pairplots\n",
    "\n",
    "> `seaborn.histplot()`  \n",
    "> `seaborn.boxplot()`  \n",
    "> `seaborn.pairplot()`  \n",
    "> `seaborn.lineplot()`  \n",
    "> Fonction pour afficher des countplot pour chaque variable :  \n",
    "<code> <font size=2>\n",
    "f, axes = plt.subplots(4,3,figsize=(17,13), sharex=False)  \n",
    "for i, feature in enumerate(df_cat_var_list):  \n",
    "    sns.countplot(data=df, x=feature, ax=axes[i%4, i//4])  \n",
    "    axes[i%4, i//4].tick_params(axis='x', labelrotation = 45)  \n",
    "      \n",
    "plt.tight_layout()  \n",
    "plt.show()  \n",
    "</font>\n",
    "</code>\n",
    "\n",
    "#### - caractéristiques des variables/attributs :  \n",
    "\n",
    "|Characteristic|Comments|\n",
    "|--------------|----------------------------------------|\n",
    "|Name||\n",
    "|Type| categorical, int/float, bounded/unbounded, text, structured, etc.|\n",
    "|% of missing values||\n",
    "|Noisiness and type of noise| stochastic, outliers, rounding errors, etc. |\n",
    "|Usefulness for the task||\n",
    "|Type of distribution| Gaussian, uniform, logarithmic, etc.|\n",
    "\n",
    "#### - séparer la target des autres  \n",
    "\n",
    "#### - Identifier des transformations possibles (log, ln, exp, sqrt, etc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prepare the data to better expose the underlying data patterns to ML\n",
    "\n",
    "#### - Recoder certaines variables catégorielles à la main, ou en créant des nouvelles variables booléennes\n",
    "\n",
    "> `sklearn.preprocessing.OrdinalEncoder`   \n",
    "> `sklearn.preprocessing.OneHotEncoder`  \n",
    "> `pd.get_dummies()`  \n",
    "> enlever les individus appartenant à une seule catégorie d'une variable et des mettre dans 'Other'  \n",
    "\n",
    "<code> <font size=2>\n",
    "def modification_categories_occurences_uniques(df : pd.DataFrame, nom_colonne:str) -> pd.DataFrame:  \n",
    "    \"\"\"modification d'un df avec ancien nom de catégorie et nouveau nom pour une colonne donnée\"\"\"  \n",
    "    replacing_df = (pd.DataFrame(  \n",
    "        df  \n",
    "        .groupby(nom_colonne)  \n",
    "        .count().loc[:, 'lat'])  \n",
    "        .rename(columns={'lat':'count'})  \n",
    "        .reset_index(names='category_old')  \n",
    "        .assign(category_new = lambda df : ['Other' if df['count'][row]<=5 else df['category_old'][row] for row in df.index] )  \n",
    "        .drop(columns='count')  \n",
    "    )  \n",
    "    df_temp = (df  \n",
    "               .replace(to_replace=list(replacing_df.category_old), value=list(replacing_df.category_new))  \n",
    "                )  \n",
    "    return df_temp  \n",
    "</font> </code>\n",
    "\n",
    "#### - Séparer un sous-ensemble de train et un autre de test /!\\ vérifier pour les variables catégorielles si les datasets sont balanced (surtout pour y mais aussi d'autres features qui peuvent induire un biais comme le sexe)\n",
    "\n",
    "> `sklearn.model_selection.train_test_split()` *(stratify)*  \n",
    "> \n",
    "\n",
    "#### - Normaliser les données (standardisation, mix-max, etc) /!\\ on fit_transform les données de train et on transforme juste les données de test\n",
    "\n",
    "> `sklearn.preprocessing.StandardScaler()`  \n",
    "\n",
    "#### - Regarder les corrélations entre variables  \n",
    "\n",
    "> `df.corr()`\n",
    "\n",
    "#### - Sélectionner les features les plus importants \n",
    "\n",
    ">\n",
    "\n",
    "#### - Exporter un dataset clean intermédiaire \n",
    "\n",
    "> `df.to_XXX()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Explore many different models and shortlist the best ones\n",
    "\n",
    "#### - choisir un modèle : classification ou régression?  \n",
    "\n",
    "<img src='https://cdn.ttgtmedia.com/rms/onlineImages/enterpriseai-machine_learning_models_cheat_sheet-f.png'/>\n",
    "\n",
    "**Régression**  \n",
    ">`sklearn.linear_model.LinearRegression`  \n",
    ">`sklearn.tree.DecisionTreeRegressor`  \n",
    ">`sklearn.ensemble.RandomForestRegressor`  \n",
    ">`sklearn.svm.LinearSVC`  \n",
    "\n",
    "**Classification**  \n",
    "> `sklearn.neighbors.KNeighborsClassifier()`\n",
    "> `sklearn.svm.SVC()`  \n",
    "> `sklearn.linear_model.SGDClassifier()`\n",
    "> `sklearn.tree.DecisionTreeClassifier()`\n",
    "> `sklearn.ensemble.RandomForestClassifier()`\n",
    "\n",
    "#### - définir un score pour évaluer la qualité du modèle (MAE, MSE, RMSE pour régression, F1, accuracy, ROC, pour classification)\n",
    "\n",
    ">`sklearn.metrics.XXX`  \n",
    "\n",
    "#### - évaluer un modèle par cross-validation (cv=5 c'est bien)\n",
    "\n",
    "> `sklearn.model_selection.cross_validate()`  \n",
    "> `sklearn.model_selection.cross_val_score()`  \n",
    "> `sklearn.model_selection.cross_val_predict()`\n",
    "\n",
    "\n",
    "#### - comparer différents modèles  \n",
    "\n",
    "#### - faire un pipeline  \n",
    "\n",
    "> `sklearn.pipeline.Pipeline`  \n",
    "> `sklearn.compose.ColumnTransformer`  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Fine-tune your models and combine them into a great solution\n",
    "\n",
    "#### - connaître les hyperparamètres des modèles  \n",
    "\n",
    "*Ressources*   \n",
    "https://stackabuse.com/understanding-svm-hyperparameters/\n",
    "\n",
    "\n",
    "#### - courbes d'apprentissage (learning curve)\n",
    "\n",
    ">`sklearn.model_selection.learning_curve()`  \n",
    ">`sklearn.model_selection.LearningCurveDisplay()`  \n",
    "\n",
    "#### - courbes de validation (validation curve)\n",
    "\n",
    "> `sklearn.model_selection.validation_curve`  \n",
    "> `sklearn.model_selection.ValidationCurveDisplay`  \n",
    "\n",
    "\n",
    "#### - grid search  \n",
    "\n",
    "> `sklearn.model_selection.GridSearchCV`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Present your solution\n",
    "\n",
    "- voir dataviz, site https://www.data-to-viz.com/  \n",
    "- voir graphviz pour afficher/exporter arbre de décision  \n",
    "\n",
    ">`sklearn.tree.export_graphviz()`  \n",
    ">`graphviz.Source()`  \n",
    ">`graph.render()`  \n",
    ">`matplotlib.image.imread()`  \n",
    ">`matplotlib.image.imshow()`  \n",
    ">`sklearn.tree.plot_tree`  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Launch, monitor and maintain your system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
